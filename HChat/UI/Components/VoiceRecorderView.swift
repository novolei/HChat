//
//  VoiceRecorderView.swift
//  HChat
//
//  Created on 2025-10-22.
//  è¯­éŸ³æ¶ˆæ¯å½•åˆ¶ UI ç»„ä»¶

import SwiftUI
import AVFoundation

/// å½•éŸ³çŠ¶æ€
enum RecordingState {
    case idle           // ç©ºé—²
    case recording      // å½•éŸ³ä¸­
    case willCancel     // å³å°†å–æ¶ˆï¼ˆæ‰‹æŒ‡æ»‘å‡ºï¼‰
}

/// è¯­éŸ³å½•åˆ¶è§†å›¾
struct VoiceRecorderView: View {
    @Binding var isRecording: Bool
    var audioRecorder: AudioRecorderManager
    var onRecordingComplete: (URL) -> Void
    var onCancel: () -> Void
    
    @State private var recordingState: RecordingState = .idle
    @State private var recordingDuration: TimeInterval = 0
    @State private var audioLevels: [CGFloat] = Array(repeating: 0.1, count: 30)
    @State private var timer: Timer?
    @State private var dragOffset: CGFloat = 0
    
    var body: some View {
        ZStack {
            // åŠé€æ˜é®ç½©
            if isRecording {
                Color.black.opacity(0.3)
                    .ignoresSafeArea()
                    .transition(.opacity)
            }
            
            // å½•éŸ³æç¤ºé¢æ¿ï¼ˆå±…ä¸­æ˜¾ç¤ºï¼‰
            if isRecording {
                VStack {
                    Spacer()
                    
                    recordingPanel
                        .offset(y: dragOffset)
                    
                    Spacer()
                        .frame(height: 200) // ä¸ºåº•éƒ¨è¾“å…¥åŒºåŸŸç•™ç©ºé—´
                }
                .transition(.scale.combined(with: .opacity))
            }
        }
        .animation(.spring(response: 0.3, dampingFraction: 0.8), value: isRecording)
        .animation(.spring(response: 0.25, dampingFraction: 0.75), value: recordingState)
        .animation(.interactiveSpring(response: 0.25, dampingFraction: 0.75), value: dragOffset)
        .gesture(
            DragGesture(minimumDistance: 0)
                .onChanged { value in
                    handleDragChange(value)
                }
                .onEnded { value in
                    handleDragEnd(value)
                }
        )
        .allowsHitTesting(isRecording)
        .onChange(of: isRecording) { _, newValue in
            if newValue {
                // å¼€å§‹å½•éŸ³æ—¶å¯åŠ¨ç›‘æ§
                DebugLogger.log("ğŸ¬ VoiceRecorderView: å¼€å§‹ç›‘æ§å½•éŸ³", level: .info)
                startMonitoring()
            } else {
                // åœæ­¢å½•éŸ³æ—¶æ¸…ç†å®šæ—¶å™¨
                DebugLogger.log("ğŸ›‘ VoiceRecorderView: åœæ­¢ç›‘æ§", level: .info)
                timer?.invalidate()
                timer = nil
            }
        }
    }
    
    // MARK: - å½•éŸ³æ§åˆ¶é¢æ¿
    
    private var recordingPanel: some View {
        VStack(spacing: ModernTheme.spacing5) {
            // å–æ¶ˆæç¤ºï¼ˆæ»‘åŠ¨æ—¶æ˜¾ç¤ºï¼‰
            if recordingState == .willCancel {
                HStack(spacing: 8) {
                    Image(systemName: "xmark.circle.fill")
                        .font(.system(size: 20))
                        .foregroundColor(.white)
                    Text("æ¾æ‰‹å–æ¶ˆå‘é€")
                        .font(ModernTheme.body.weight(.medium))
                        .foregroundColor(.white)
                }
                .padding(.vertical, 12)
                .padding(.horizontal, 24)
                .background(
                    Capsule()
                        .fill(Color.red)
                )
                .shadow(color: .red.opacity(0.3), radius: 8, y: 4)
            } else {
                // å½•éŸ³ä¸­çš„ç•Œé¢
                VStack(spacing: ModernTheme.spacing4) {
                    // æ³¢å½¢å¯è§†åŒ– - ä½¿ç”¨ç™½è‰²å’Œé»„ç»¿è‰²æ¸å˜ï¼Œæ›´æ˜æ˜¾
                    HStack(spacing: 2) {
                        ForEach(0..<audioLevels.count, id: \.self) { index in
                            Capsule()
                                .fill(
                                    LinearGradient(
                                        colors: [Color.white, Color(red: 0.5, green: 1.0, blue: 0.5)],
                                        startPoint: .bottom,
                                        endPoint: .top
                                    )
                                )
                                .frame(width: 2.5, height: max(8, audioLevels[index] * 70))
                                .shadow(color: Color.white.opacity(0.5), radius: 2)
                                .animation(.easeInOut(duration: 0.15), value: audioLevels[index])
                        }
                    }
                    .frame(height: 70)
                    
                    // å½•éŸ³æ—¶é•¿
                    Text(formatDuration(recordingDuration))
                        .font(ModernTheme.title2.monospacedDigit())
                        .foregroundColor(.white)
                        .shadow(color: .black.opacity(0.3), radius: 2)
                    
                    // æç¤ºæ–‡æœ¬
                    HStack(spacing: 6) {
                        Image(systemName: "arrow.up")
                            .font(.system(size: 12, weight: .semibold))
                        Text("ä¸Šæ»‘å–æ¶ˆ")
                            .font(ModernTheme.caption)
                    }
                    .foregroundColor(.white.opacity(0.9))
                    .shadow(color: .black.opacity(0.3), radius: 2)
                }
                .padding(.vertical, ModernTheme.spacing5)
                .padding(.horizontal, 40) // å¢åŠ æ°´å¹³å†…è¾¹è·ï¼Œè®©é¢æ¿æ›´å®½
                .frame(maxWidth: 340) // è®¾ç½®æœ€å¤§å®½åº¦
                .background(
                    RoundedRectangle(cornerRadius: 24, style: .continuous)
                        .fill(
                            LinearGradient(
                                colors: [
                                    Color(red: 0.3, green: 0.4, blue: 0.9).opacity(0.95), // æ·±è“è‰²
                                    Color(red: 0.5, green: 0.3, blue: 0.8).opacity(0.95)  // ç´«è‰²
                                ],
                                startPoint: .topLeading,
                                endPoint: .bottomTrailing
                            )
                        )
                        .shadow(color: Color.black.opacity(0.3), radius: 20, y: 10)
                )
            }
        }
    }
    
    // MARK: - æ‰‹åŠ¿å¤„ç†
    
    private func handleDragChange(_ value: DragGesture.Value) {
        // åªå¤„ç†å‚ç›´æ–¹å‘çš„æ»‘åŠ¨
        let translation = value.translation.height
        
        // å‘ä¸Šæ»‘åŠ¨è¶…è¿‡ 80pt æ—¶æ˜¾ç¤ºå–æ¶ˆæç¤º
        if translation < -80 {
            recordingState = .willCancel
            dragOffset = translation
        } else {
            recordingState = .recording
            dragOffset = min(0, translation) // åªå…è®¸å‘ä¸Šæ»‘åŠ¨
        }
    }
    
    private func handleDragEnd(_ value: DragGesture.Value) {
        dragOffset = 0
        
        if recordingState == .willCancel {
            // å–æ¶ˆå½•éŸ³
            cancelRecording()
        } else {
            // å®Œæˆå½•éŸ³
            finishRecording()
        }
    }
    
    // MARK: - å½•éŸ³æ§åˆ¶
    
    /// å¯åŠ¨å®šæ—¶å™¨ç›‘æ§å½•éŸ³çŠ¶æ€
    func startMonitoring() {
        recordingState = .recording
        
        DebugLogger.log("ğŸ¤ å¼€å§‹ç›‘æ§å½•éŸ³çŠ¶æ€ï¼ŒisRecording=\(audioRecorder.isRecording)", level: .info)
        
        // å¯åŠ¨å®šæ—¶å™¨æ›´æ–°æ—¶é•¿å’Œæ³¢å½¢
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [self] _ in
            // ä» audioRecorder è·å–çœŸå®æ•°æ®
            let newDuration = audioRecorder.duration
            let newLevel = audioRecorder.getNormalizedLevel()
            
            // æ›´æ–°æ—¶é•¿
            recordingDuration = newDuration
            
            // æ›´æ–°éŸ³é¢‘ç”µå¹³
            audioLevels.removeFirst()
            audioLevels.append(newLevel)
            
            // å¶å°”è¾“å‡ºæ—¥å¿—
            if Int(newDuration * 10) % 10 == 0 {
                DebugLogger.log("ğŸ“Š å½•éŸ³ä¸­: \(newDuration)s, level=\(newLevel)", level: .debug)
            }
            
            // æœ€å¤§å½•éŸ³æ—¶é•¿ 60 ç§’
            if recordingDuration >= 60 {
                finishRecording()
            }
        }
        
        DebugLogger.log("âœ… å®šæ—¶å™¨å·²å¯åŠ¨", level: .info)
    }
    
    private func finishRecording() {
        timer?.invalidate()
        timer = nil
        
        isRecording = false
        recordingState = .idle
        dragOffset = 0
        
        HapticManager.notification(type: .success)
        DebugLogger.log("âœ… å½•éŸ³å®Œæˆï¼Œæ—¶é•¿: \(recordingDuration)s", level: .info)
        
        // åœæ­¢å½•éŸ³å¹¶è·å–æ–‡ä»¶ URL
        if let recordingURL = audioRecorder.stopRecording() {
            onRecordingComplete(recordingURL)
        }
    }
    
    private func cancelRecording() {
        timer?.invalidate()
        timer = nil
        
        isRecording = false
        recordingState = .idle
        dragOffset = 0
        
        HapticManager.notification(type: .warning)
        DebugLogger.log("âŒ å½•éŸ³å·²å–æ¶ˆ", level: .info)
        
        // å–æ¶ˆå½•éŸ³
        audioRecorder.cancelRecording()
        onCancel()
    }
    
    // MARK: - è¾…åŠ©æ–¹æ³•
    
    private func formatDuration(_ duration: TimeInterval) -> String {
        let minutes = Int(duration) / 60
        let seconds = Int(duration) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
}

// MARK: - é¢„è§ˆ

#Preview("å½•éŸ³ä¸­") {
    ZStack {
        ModernTheme.twilightGradient
            .ignoresSafeArea()
        
        VStack {
            Spacer()
            Text("èŠå¤©æ¶ˆæ¯åŒºåŸŸ")
                .foregroundColor(.white)
            Spacer()
        }
        
        VoiceRecorderView(
            isRecording: .constant(true),
            audioRecorder: AudioRecorderManager(),
            onRecordingComplete: { _ in },
            onCancel: {}
        )
    }
}
