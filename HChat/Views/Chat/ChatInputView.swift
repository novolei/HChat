//
//  ChatInputView.swift
//  HChat
//
//  Created by AI Assistant on 2025/10/21.
//  âœ¨ UIä¼˜åŒ–ï¼šç°ä»£åŒ–èŠå¤©è¾“å…¥æ¡†ï¼Œä¼˜é›…çš„è®¾è®¡å’Œæµç•…çš„äº¤äº’
//

import SwiftUI

struct ChatInputView: View {
    var client: HackChatClient
    @Binding var inputText: String
    var onSend: () -> Void
    var onAttachment: () -> Void
    
    @FocusState private var isInputFocused: Bool
    @State private var lastTypingTime: Date?
    @State private var isRecordingVoice = false
    @State private var audioRecorder = AudioRecorderManager()
    
    var body: some View {
        VStack(spacing: 0) {
            // âœ¨ P1: å›å¤é¢„è§ˆæ¡ï¼ˆä¼˜åŒ–ï¼šç§»é™¤å¤æ‚è¿‡æ¸¡åŠ¨ç”»ï¼‰
            if let replyTo = client.replyManager.replyingTo {
                ReplyPreviewBar(
                    replyTo: replyTo,
                    onCancel: {
                        client.replyManager.clearReply()
                    }
                )
                .transition(.opacity)
            }
            
            // è¾“å…¥åŒºåŸŸ
            HStack(alignment: .bottom, spacing: HChatTheme.mediumSpacing) {
                // é™„ä»¶æŒ‰é’®
                Button {
                    onAttachment()
                    HapticManager.impact(style: .light)
                } label: {
                    Image(systemName: "paperclip")
                        .font(.system(size: 20, weight: .medium))
                        .foregroundStyle(.white)
                        .padding(12)
                        .background(
                            Circle()
                                .fill(LinearGradient(colors: [ModernTheme.accent, ModernTheme.secondaryAccent], startPoint: .topLeading, endPoint: .bottomTrailing))
                        )
                }
                .buttonStyle(.plain)
                
                // è¾“å…¥æ¡†
                TextField("è¾“å…¥æ¶ˆæ¯...", text: $inputText, axis: .vertical)
                    .lineLimit(1...6)
                    .font(HChatTheme.bodyFont)
                    .focused($isInputFocused)
                    .onChange(of: inputText) { _, newValue in
                        handleTypingChange(newValue)
                    }
                    .onSubmit {
                        if !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                            onSend()
                        }
                    }
                    .padding(.horizontal, HChatTheme.mediumSpacing)
                    .padding(.vertical, HChatTheme.mediumSpacing)
                    .background(
                        RoundedRectangle(cornerRadius: ModernTheme.extraLargeRadius, style: .continuous)
                            .fill(.ultraThinMaterial)
                    )
                    .overlay(
                        RoundedRectangle(cornerRadius: ModernTheme.extraLargeRadius, style: .continuous)
                            .stroke(LinearGradient(colors: [ModernTheme.accent.opacity(isInputFocused ? 0.6 : 0.2), ModernTheme.secondaryAccent.opacity(isInputFocused ? 0.6 : 0.2)], startPoint: .topLeading, endPoint: .bottomTrailing), lineWidth: 1.2)
                    )
                
                // å‘é€/è¯­éŸ³æŒ‰é’®
                if inputText.isEmpty {
                    // è¯­éŸ³å½•åˆ¶æŒ‰é’®
                    voiceButton
                } else {
                    // å‘é€æŒ‰é’®
                    Button {
                        onSend()
                        HapticManager.impact(style: .medium)
                    } label: {
                        Image(systemName: "paperplane.fill")
                            .font(.system(size: 20, weight: .semibold))
                            .foregroundStyle(.white)
                            .padding(12)
                            .background(
                                Circle()
                                    .fill(LinearGradient(colors: [ModernTheme.accent, ModernTheme.secondaryAccent], startPoint: .topLeading, endPoint: .bottomTrailing))
                            )
                    }
                    .buttonStyle(.plain)
                    .transition(.scale.combined(with: .opacity))
                }
            }
            .padding(.horizontal, ModernTheme.spacing5)
            .padding(.vertical, ModernTheme.spacing3)
        }
        .animation(HChatTheme.standardAnimation, value: client.replyManager.replyingTo != nil)
        .animation(HChatTheme.quickAnimation, value: inputText.isEmpty)
        .overlay(
            // è¯­éŸ³å½•åˆ¶ç•Œé¢ï¼ˆä½¿ç”¨ overlay é¿å…å½±å“å¸ƒå±€ï¼‰
            VoiceRecorderView(
                isRecording: $isRecordingVoice,
                onRecordingComplete: handleVoiceRecorded,
                onCancel: handleVoiceCancel
            )
            .allowsHitTesting(isRecordingVoice)
        )
    }
    
    // MARK: - è¯­éŸ³å½•åˆ¶æŒ‰é’®
    
    private var voiceButton: some View {
        Button {
            // å ä½ï¼Œå®é™…é€šè¿‡ simultaneousGesture å¤„ç†
        } label: {
            Circle()
                .fill(LinearGradient(colors: [ModernTheme.accent, ModernTheme.secondaryAccent], startPoint: .topLeading, endPoint: .bottomTrailing))
                .frame(width: 44, height: 44)
                .overlay(
                    Image(systemName: "waveform")
                        .font(.system(size: 20, weight: .semibold))
                        .foregroundStyle(.white)
                )
        }
        .buttonStyle(.plain)
        .simultaneousGesture(
            // ä½¿ç”¨ DragGesture æ¥æ£€æµ‹æŒ‰ä¸‹å’Œæ»‘åŠ¨
            DragGesture(minimumDistance: 0)
                .onChanged { _ in
                    // é¦–æ¬¡æŒ‰ä¸‹æ—¶å¼€å§‹å½•éŸ³
                    if !isRecordingVoice {
                        startVoiceRecording()
                    }
                }
        )
    }
    
    // MARK: - æ­£åœ¨è¾“å…¥å¤„ç†
    
    /// å¤„ç†è¾“å…¥å˜åŒ–ï¼Œå‘é€æ­£åœ¨è¾“å…¥äº‹ä»¶ï¼ˆèŠ‚æµï¼šæ¯ 2 ç§’æœ€å¤šå‘é€ä¸€æ¬¡ï¼‰
    private func handleTypingChange(_ text: String) {
        // å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œé‡ç½® lastTypingTimeï¼ˆç”¨æˆ·å‘é€æ¶ˆæ¯æˆ–æ¸…ç©ºè¾“å…¥æ¡†ï¼‰
        guard !text.isEmpty else {
            lastTypingTime = nil
            return
        }
        
        let now = Date()
        
        // å¦‚æœè·ç¦»ä¸Šæ¬¡å‘é€ä¸åˆ° 2 ç§’ï¼Œä¸å‘é€
        if let lastTime = lastTypingTime, now.timeIntervalSince(lastTime) < 2.0 {
            return
        }
        
        // å‘é€æ­£åœ¨è¾“å…¥äº‹ä»¶
        client.typingIndicatorManager.sendTypingStatus(channel: client.currentChannel)
        lastTypingTime = now
    }
    
    // MARK: - è¯­éŸ³å½•åˆ¶å¤„ç†
    
    private func startVoiceRecording() {
        Task {
            // è¯·æ±‚éº¦å…‹é£æƒé™
            let granted = await audioRecorder.requestPermission()
            guard granted else {
                DebugLogger.log("âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»", level: .warning)
                return
            }
            
            // å¼€å§‹å½•éŸ³
            do {
                try audioRecorder.startRecording()
                isRecordingVoice = true
                HapticManager.impact(style: .medium)
            } catch {
                DebugLogger.log("âŒ å¼€å§‹å½•éŸ³å¤±è´¥: \(error.localizedDescription)", level: .error)
            }
        }
    }
    
    private func handleVoiceRecorded(_ url: URL) {
        // TODO: åŠ å¯†å¹¶ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
        DebugLogger.log("ğŸ¤ å½•éŸ³å®Œæˆ: \(url.path)", level: .info)
        
        // åœæ­¢å½•éŸ³
        if let recordingURL = audioRecorder.stopRecording() {
            DebugLogger.log("ğŸ“ å½•éŸ³æ–‡ä»¶: \(recordingURL.path)", level: .info)
            // TODO: å‘é€è¯­éŸ³æ¶ˆæ¯
        }
    }
    
    private func handleVoiceCancel() {
        audioRecorder.cancelRecording()
        DebugLogger.log("âŒ å½•éŸ³å·²å–æ¶ˆ", level: .info)
    }
}

// MARK: - ğŸ¯ è§¦è§‰åé¦ˆç®¡ç†å™¨

enum HapticManager {
    static func impact(style: UIImpactFeedbackGenerator.FeedbackStyle) {
        let generator = UIImpactFeedbackGenerator(style: style)
        generator.impactOccurred()
    }
    
    static func notification(type: UINotificationFeedbackGenerator.FeedbackType) {
        let generator = UINotificationFeedbackGenerator()
        generator.notificationOccurred(type)
    }
    
    static func selection() {
        let generator = UISelectionFeedbackGenerator()
        generator.selectionChanged()
    }
}

