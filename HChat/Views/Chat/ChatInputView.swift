//
//  ChatInputView.swift
//  HChat
//
//  Created by AI Assistant on 2025/10/21.
//  âœ¨ UIä¼˜åŒ–ï¼šç°ä»£åŒ–èŠå¤©è¾“å…¥æ¡†ï¼Œä¼˜é›…çš„è®¾è®¡å’Œæµç•…çš„äº¤äº’
//

import SwiftUI

struct ChatInputView: View {
    var client: HackChatClient
    @Binding var inputText: String
    var onSend: () -> Void
    var onAttachment: () -> Void
    
    @FocusState private var isInputFocused: Bool
    @State private var lastTypingTime: Date?
    @State private var isRecordingVoice = false
    @State private var audioRecorder = AudioRecorderManager()
    @State private var voicePreview: (url: URL, duration: TimeInterval, waveform: [CGFloat])? = nil
    @State private var keepKeyboardForPreview = false
    
    var body: some View {
        VStack(spacing: 0) {
            // âœ¨ P1: å›å¤é¢„è§ˆæ¡ï¼ˆä¼˜åŒ–ï¼šç§»é™¤å¤æ‚è¿‡æ¸¡åŠ¨ç”»ï¼‰
            if let replyTo = client.replyManager.replyingTo {
                ReplyPreviewBar(
                    replyTo: replyTo,
                    onCancel: {
                        client.replyManager.clearReply()
                    }
                )
                .transition(.opacity)
            }
            
            // è¯­éŸ³é¢„è§ˆä¸è¾“å…¥åŒºåŸŸå åŠ 
            ZStack {
                inputArea
                    .opacity(voicePreview == nil ? 1 : 0)
                    .allowsHitTesting(voicePreview == nil)

                if let preview = voicePreview {
                    VoiceMessagePreview(
                        duration: preview.duration,
                        waveformData: preview.waveform,
                        audioURL: preview.url,
                        onSend: {
                            sendVoiceMessage()
                        },
                        onCancel: {
                            cancelVoicePreview()
                        }
                    )
                    .transition(.move(edge: .bottom).combined(with: .opacity))
                    .onAppear {
                        DebugLogger.log("ğŸ‘€ VoiceMessagePreview å·²æ˜¾ç¤º", level: .info)
                        DispatchQueue.main.async {
                            if keepKeyboardForPreview {
                                isInputFocused = true
                            } else {
                                isInputFocused = false
                            }
                        }
                    }
                }
            }
            .padding(.horizontal, ModernTheme.spacing5)
            .padding(.vertical, ModernTheme.spacing3)
        }
        .animation(HChatTheme.standardAnimation, value: client.replyManager.replyingTo != nil)
        .animation(HChatTheme.quickAnimation, value: inputText.isEmpty)
        .animation(HChatTheme.standardAnimation, value: voicePreview != nil)
        .overlay(
            // è¯­éŸ³å½•åˆ¶ç•Œé¢ï¼ˆä½¿ç”¨ overlay é¿å…å½±å“å¸ƒå±€ï¼‰
            VoiceRecorderView(
                isRecording: $isRecordingVoice,
                audioRecorder: audioRecorder,
                onRecordingComplete: handleVoiceRecorded,
                onCancel: handleVoiceCancel
            )
            .allowsHitTesting(isRecordingVoice)
        )
    }
    
    // MARK: - è¯­éŸ³å½•åˆ¶æŒ‰é’®
    
    private var voiceButton: some View {
        Button {
            // å ä½ï¼Œå®é™…é€šè¿‡ simultaneousGesture å¤„ç†
        } label: {
            Circle()
                .fill(LinearGradient(colors: [ModernTheme.accent, ModernTheme.secondaryAccent], startPoint: .topLeading, endPoint: .bottomTrailing))
                .frame(width: 44, height: 44)
                .overlay(
                    Image(systemName: "waveform")
                        .font(.system(size: 20, weight: .semibold))
                        .foregroundStyle(.white)
                )
        }
        .buttonStyle(.plain)
        .simultaneousGesture(
            // ä½¿ç”¨ DragGesture æ¥æ£€æµ‹æŒ‰ä¸‹å’Œæ»‘åŠ¨
            DragGesture(minimumDistance: 0)
                .onChanged { _ in
                    // é¦–æ¬¡æŒ‰ä¸‹æ—¶å¼€å§‹å½•éŸ³
                    if !isRecordingVoice {
                        startVoiceRecording()
                    }
                }
        )
    }
    
    // MARK: - æ­£åœ¨è¾“å…¥å¤„ç†
    
    /// å¤„ç†è¾“å…¥å˜åŒ–ï¼Œå‘é€æ­£åœ¨è¾“å…¥äº‹ä»¶ï¼ˆèŠ‚æµï¼šæ¯ 2 ç§’æœ€å¤šå‘é€ä¸€æ¬¡ï¼‰
    private func handleTypingChange(_ text: String) {
        // å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œé‡ç½® lastTypingTimeï¼ˆç”¨æˆ·å‘é€æ¶ˆæ¯æˆ–æ¸…ç©ºè¾“å…¥æ¡†ï¼‰
        guard !text.isEmpty else {
            lastTypingTime = nil
            return
        }
        
        let now = Date()
        
        // å¦‚æœè·ç¦»ä¸Šæ¬¡å‘é€ä¸åˆ° 2 ç§’ï¼Œä¸å‘é€
        if let lastTime = lastTypingTime, now.timeIntervalSince(lastTime) < 2.0 {
            return
        }
        
        // å‘é€æ­£åœ¨è¾“å…¥äº‹ä»¶
        client.typingIndicatorManager.sendTypingStatus(channel: client.currentChannel)
        lastTypingTime = now
    }
    
    // MARK: - è¯­éŸ³å½•åˆ¶å¤„ç†
    
    private func startVoiceRecording() {
        Task {
            // è¯·æ±‚éº¦å…‹é£æƒé™
            let granted = await audioRecorder.requestPermission()
            guard granted else {
                DebugLogger.log("âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»", level: .warning)
                return
            }
            
            // å¼€å§‹å½•éŸ³
            do {
                try audioRecorder.startRecording()
                isRecordingVoice = true
                HapticManager.impact(style: .medium)
            } catch {
                DebugLogger.log("âŒ å¼€å§‹å½•éŸ³å¤±è´¥: \(error.localizedDescription)", level: .error)
            }
        }
    }
    
    private func handleVoiceRecorded(_ url: URL) {
        DebugLogger.log("ğŸ¤ å½•éŸ³å®Œæˆ: \(url.path)", level: .info)
        
        // è·å–å½•éŸ³æ—¶é•¿
        let duration = audioRecorder.duration
        DebugLogger.log("â±ï¸ å½•éŸ³æ—¶é•¿: \(duration)s", level: .info)
        
        // è·å–æ³¢å½¢æ•°æ®ï¼ˆä» AudioRecorderManager çš„å†å²è®°å½•ï¼‰
        let waveform = generateWaveformData(duration: duration)
        DebugLogger.log("ğŸ“Š æ³¢å½¢æ•°æ®: \(waveform.count) ä¸ªé‡‡æ ·ç‚¹", level: .info)
        
        // æ˜¾ç¤ºé¢„è§ˆ
        keepKeyboardForPreview = isInputFocused
        voicePreview = (url: url, duration: duration, waveform: waveform)
        DebugLogger.log("âœ… è¯­éŸ³é¢„è§ˆå·²è®¾ç½®", level: .info)
    }
    
    private func sendVoiceMessage() {
        guard let preview = voicePreview else { return }
        
        // åŠ å¯†å¹¶ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
        Task {
            do {
                let attachment = try await uploadVoiceFile(url: preview.url)
                DebugLogger.log("âœ… è¯­éŸ³æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: \(attachment.filename)", level: .info)
                
                // å‘é€è¯­éŸ³æ¶ˆæ¯åˆ°èŠå¤©
                await MainActor.run {
                    var enriched = attachment
                    enriched.duration = preview.duration
                    enriched.waveform = preview.waveform
                    DebugLogger.log("ğŸ“¤ å‡†å¤‡å‘é€è¯­éŸ³é™„ä»¶ - duration: \(preview.duration)s, waveform: \(preview.waveform.count) samples", level: .info)
                    client.sendAttachment(enriched)
                    DebugLogger.log("âœ… è¯­éŸ³æ¶ˆæ¯å·²å‘é€åˆ° client", level: .info)
                    voicePreview = nil // æ¸…é™¤é¢„è§ˆ
                    keepKeyboardForPreview = false
                }
            } catch {
                DebugLogger.log("âŒ è¯­éŸ³æ–‡ä»¶ä¸Šä¼ å¤±è´¥: \(error.localizedDescription)", level: .error)
            }
        }
    }
    
    private func cancelVoicePreview() {
        if let preview = voicePreview {
            // åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            try? FileManager.default.removeItem(at: preview.url)
        }
        voicePreview = nil
        keepKeyboardForPreview = false
        HapticManager.impact(style: .light)
    }
    
    private func generateWaveformData(duration: TimeInterval) -> [CGFloat] {
        // ç”Ÿæˆ40ä¸ªé‡‡æ ·ç‚¹çš„æ³¢å½¢æ•°æ®
        // å®é™…åº”è¯¥ä»éŸ³é¢‘æ–‡ä»¶ä¸­æå–ï¼Œè¿™é‡Œä½¿ç”¨éšæœºæ•°æ¨¡æ‹Ÿ
        return (0..<40).map { _ in CGFloat.random(in: 0.3...1.0) }
    }
    
    private func handleVoiceCancel() {
        DebugLogger.log("âŒ å½•éŸ³å·²å–æ¶ˆ", level: .info)
    }
    
    /// ä¸Šä¼ è¯­éŸ³æ–‡ä»¶ï¼ˆåŠ å¯†ï¼‰
    private func uploadVoiceFile(url: URL) async throws -> Attachment {
        let uploader = Services.uploader
        let passphrase = client.currentChannel // ä½¿ç”¨é¢‘é“åä½œä¸ºå¯†ç 
        
        // åŠ å¯†å¹¶ä¸Šä¼ 
        return try await uploader.encryptAndUploadFile(
            fileURL: url,
            filename: "voice_\(Int(Date().timeIntervalSince1970)).m4a",
            originalContentType: "audio/m4a",
            passphrase: passphrase,
            objectKeyPrefix: "rooms/\(client.currentChannel)"
        )
    }
}

// MARK: - ğŸ¯ è§¦è§‰åé¦ˆç®¡ç†å™¨

enum HapticManager {
    static func impact(style: UIImpactFeedbackGenerator.FeedbackStyle) {
        let generator = UIImpactFeedbackGenerator(style: style)
        generator.impactOccurred()
    }
    
    static func notification(type: UINotificationFeedbackGenerator.FeedbackType) {
        let generator = UINotificationFeedbackGenerator()
        generator.notificationOccurred(type)
    }
    
    static func selection() {
        let generator = UISelectionFeedbackGenerator()
        generator.selectionChanged()
    }
}

private extension ChatInputView {
    var inputArea: some View {
        HStack(alignment: .bottom, spacing: HChatTheme.mediumSpacing) {
            Button {
                onAttachment()
                HapticManager.impact(style: .light)
            } label: {
                Image(systemName: "paperclip")
                    .font(.system(size: 20, weight: .medium))
                    .foregroundStyle(.white)
                    .padding(12)
                    .background(
                        Circle()
                            .fill(LinearGradient(colors: [ModernTheme.accent, ModernTheme.secondaryAccent], startPoint: .topLeading, endPoint: .bottomTrailing))
                    )
            }
            .buttonStyle(.plain)

            TextField("è¾“å…¥æ¶ˆæ¯...", text: $inputText, axis: .vertical)
                .lineLimit(1...6)
                .font(HChatTheme.bodyFont)
                .focused($isInputFocused)
                .onChange(of: inputText) { _, newValue in
                    handleTypingChange(newValue)
                }
                .onSubmit {
                    if !inputText.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                        onSend()
                    }
                }
                .padding(.horizontal, HChatTheme.mediumSpacing)
                .padding(.vertical, HChatTheme.mediumSpacing)
                .background(
                    RoundedRectangle(cornerRadius: ModernTheme.extraLargeRadius, style: .continuous)
                        .fill(.ultraThinMaterial)
                )
                .overlay(
                    RoundedRectangle(cornerRadius: ModernTheme.extraLargeRadius, style: .continuous)
                        .stroke(
                            LinearGradient(
                                colors: [
                                    ModernTheme.accent.opacity(isInputFocused ? 0.6 : 0.2),
                                    ModernTheme.secondaryAccent.opacity(isInputFocused ? 0.6 : 0.2)
                                ],
                                startPoint: .topLeading,
                                endPoint: .bottomTrailing
                            ),
                            lineWidth: 1.2
                        )
                )

            if inputText.isEmpty {
                voiceButton
            } else {
                Button {
                    onSend()
                    HapticManager.impact(style: .medium)
                } label: {
                    Image(systemName: "paperplane.fill")
                        .font(.system(size: 20, weight: .semibold))
                        .foregroundStyle(.white)
                        .padding(12)
                        .background(
                            Circle()
                                .fill(LinearGradient(colors: [ModernTheme.accent, ModernTheme.secondaryAccent], startPoint: .topLeading, endPoint: .bottomTrailing))
                        )
                }
                .buttonStyle(.plain)
                .transition(.scale.combined(with: .opacity))
            }
        }
    }
}

